Epoch 1/200: 100%|██████████| 161/161 [00:08<00:00, 20.01it/s, loss (batch)=5.5] 
Epoch 1/200: 100%|██████████| 52/52 [00:38<00:00,  1.35it/s, val_loss (batch)=65.6]
Epoch 1, average_train_loss: 0.2762789464161859
Epoch 1, average_train_loss: 0.2762789464161859, average_val_loss: 0.9809613996749585
Saved model state dict: ./model/transformer_1.pth
Epoch 2/200: 100%|██████████| 161/161 [00:06<00:00, 23.26it/s, loss (batch)=2.81]
Epoch 2, average_train_loss: 0.0537687015631036
Saved model state dict: ./model/transformer_2.pth
Epoch 3/200: 100%|██████████| 161/161 [00:06<00:00, 23.15it/s, loss (batch)=1.69]
Epoch 3, average_train_loss: 0.03138884956894092
Saved model state dict: ./model/transformer_3.pth
Epoch 4/200: 100%|██████████| 161/161 [00:06<00:00, 24.35it/s, loss (batch)=1.39]
Epoch 4, average_train_loss: 0.026155248288696545
Saved model state dict: ./model/transformer_4.pth
Epoch 5/200: 100%|██████████| 161/161 [00:06<00:00, 23.11it/s, loss (batch)=1.59]
Epoch 5, average_train_loss: 0.024136231443057363
Saved model state dict: ./model/transformer_5.pth
Epoch 6/200: 100%|██████████| 161/161 [00:06<00:00, 23.79it/s, loss (batch)=1.38]
Epoch 6, average_train_loss: 0.02179573312069215
Saved model state dict: ./model/transformer_6.pth
Epoch 7/200: 100%|██████████| 161/161 [00:38<00:00,  4.21it/s, loss (batch)=1.27]
Epoch 7, average_train_loss: 0.01933043581179366
Saved model state dict: ./model/transformer_7.pth
Epoch 8/200: 100%|██████████| 161/161 [01:14<00:00,  2.17it/s, loss (batch)=0.891]
Epoch 8, average_train_loss: 0.01799862955922609
Saved model state dict: ./model/transformer_8.pth
Epoch 9/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=1.21] 
Epoch 9, average_train_loss: 0.01713840294716105
Saved model state dict: ./model/transformer_9.pth
Epoch 10/200: 100%|██████████| 161/161 [00:06<00:00, 23.77it/s, loss (batch)=0.867]
Epoch 10, average_train_loss: 0.015827825887081697
Saved model state dict: ./model/transformer_10.pth
Epoch 11/200: 100%|██████████| 161/161 [00:06<00:00, 23.84it/s, loss (batch)=0.882]
Epoch 11/200: 100%|██████████| 52/52 [00:39<00:00,  1.31it/s, val_loss (batch)=16.1]
Epoch 11, average_train_loss: 0.014742949990405521
Epoch 11, average_train_loss: 0.014742949990405521, average_val_loss: 0.5105043319160005
Saved model state dict: ./model/transformer_11.pth
Epoch 12/200: 100%|██████████| 161/161 [00:06<00:00, 24.71it/s, loss (batch)=0.819]
Epoch 12, average_train_loss: 0.013541832012968005
Saved model state dict: ./model/transformer_12.pth
Epoch 13/200: 100%|██████████| 161/161 [00:06<00:00, 24.53it/s, loss (batch)=0.811]
Epoch 13, average_train_loss: 0.012944569191311364
Saved model state dict: ./model/transformer_13.pth
Epoch 14/200: 100%|██████████| 161/161 [00:06<00:00, 24.66it/s, loss (batch)=0.895]
Epoch 14, average_train_loss: 0.012118923589739695
Saved model state dict: ./model/transformer_14.pth
Epoch 15/200: 100%|██████████| 161/161 [00:06<00:00, 24.06it/s, loss (batch)=0.654]
Epoch 15, average_train_loss: 0.01149242254344939
Saved model state dict: ./model/transformer_15.pth
Epoch 16/200: 100%|██████████| 161/161 [00:50<00:00,  3.20it/s, loss (batch)=0.653]
Epoch 16, average_train_loss: 0.010512971033444472
Saved model state dict: ./model/transformer_16.pth
Epoch 17/200: 100%|██████████| 161/161 [01:12<00:00,  2.23it/s, loss (batch)=0.644]
Epoch 17, average_train_loss: 0.01005300370913339
Saved model state dict: ./model/transformer_17.pth
Epoch 18/200: 100%|██████████| 161/161 [01:11<00:00,  2.26it/s, loss (batch)=0.61] 
Epoch 18, average_train_loss: 0.009720040266886288
Saved model state dict: ./model/transformer_18.pth
Epoch 19/200: 100%|██████████| 161/161 [00:33<00:00,  4.82it/s, loss (batch)=0.583]
Epoch 19, average_train_loss: 0.009201592403875086
Saved model state dict: ./model/transformer_19.pth
Epoch 20/200: 100%|██████████| 161/161 [01:08<00:00,  2.34it/s, loss (batch)=0.49] 
Epoch 20, average_train_loss: 0.008739616380961431
Saved model state dict: ./model/transformer_20.pth
Epoch 21/200: 100%|██████████| 161/161 [01:10<00:00,  2.28it/s, loss (batch)=0.508]
Epoch 21/200: 100%|██████████| 52/52 [07:01<00:00,  8.11s/it, val_loss (batch)=24.1]
Epoch 21, average_train_loss: 0.0081456844894501
Epoch 21, average_train_loss: 0.0081456844894501, average_val_loss: 0.5223314486265255
Saved model state dict: ./model/transformer_21.pth
Epoch 22/200: 100%|██████████| 161/161 [00:06<00:00, 25.45it/s, loss (batch)=0.478]
Epoch 22, average_train_loss: 0.007714530431484226
Saved model state dict: ./model/transformer_22.pth
Epoch 23/200: 100%|██████████| 161/161 [00:06<00:00, 25.99it/s, loss (batch)=0.484]
Epoch 23, average_train_loss: 0.007430067174256446
Saved model state dict: ./model/transformer_23.pth
Epoch 24/200: 100%|██████████| 161/161 [00:06<00:00, 24.69it/s, loss (batch)=0.428]
Epoch 24, average_train_loss: 0.007154975209525658
Saved model state dict: ./model/transformer_24.pth
Epoch 25/200: 100%|██████████| 161/161 [00:06<00:00, 23.67it/s, loss (batch)=0.488]
Epoch 25, average_train_loss: 0.006993691790651106
Saved model state dict: ./model/transformer_25.pth
Epoch 26/200: 100%|██████████| 161/161 [00:44<00:00,  3.65it/s, loss (batch)=0.405]
Epoch 26, average_train_loss: 0.006449576010191468
Saved model state dict: ./model/transformer_26.pth
Epoch 27/200: 100%|██████████| 161/161 [00:41<00:00,  3.90it/s, loss (batch)=0.373]
Epoch 27, average_train_loss: 0.006146804568549367
Saved model state dict: ./model/transformer_27.pth
Epoch 28/200: 100%|██████████| 161/161 [00:53<00:00,  3.02it/s, loss (batch)=0.376]
Epoch 28, average_train_loss: 0.005814720273029501
Saved model state dict: ./model/transformer_28.pth
Epoch 29/200: 100%|██████████| 161/161 [00:51<00:00,  3.10it/s, loss (batch)=0.369]
Epoch 29, average_train_loss: 0.005756051402588753
Saved model state dict: ./model/transformer_29.pth
Epoch 30/200: 100%|██████████| 161/161 [00:51<00:00,  3.12it/s, loss (batch)=0.321]
Epoch 30, average_train_loss: 0.005210724049243717
Saved model state dict: ./model/transformer_30.pth
Epoch 31/200: 100%|██████████| 161/161 [00:54<00:00,  2.98it/s, loss (batch)=0.358]
Epoch 31/200: 100%|██████████| 52/52 [06:11<00:00,  7.14s/it, val_loss (batch)=33.2]
Epoch 31, average_train_loss: 0.005191696362820254
Epoch 31, average_train_loss: 0.005191696362820254, average_val_loss: 0.5192976330972319
Saved model state dict: ./model/transformer_31.pth
Epoch 32/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.263]
Epoch 32, average_train_loss: 0.00503364600362444
Saved model state dict: ./model/transformer_32.pth
Epoch 33/200: 100%|██████████| 161/161 [00:59<00:00,  2.71it/s, loss (batch)=0.311]
Epoch 33, average_train_loss: 0.00481071667984417
Saved model state dict: ./model/transformer_33.pth
Epoch 34/200: 100%|██████████| 161/161 [01:03<00:00,  2.53it/s, loss (batch)=0.293]
Epoch 34, average_train_loss: 0.004581885337364882
Saved model state dict: ./model/transformer_34.pth
Epoch 35/200: 100%|██████████| 161/161 [01:06<00:00,  2.42it/s, loss (batch)=0.255]
Epoch 35, average_train_loss: 0.004543127245738509
Saved model state dict: ./model/transformer_35.pth
Epoch 36/200: 100%|██████████| 161/161 [01:06<00:00,  2.43it/s, loss (batch)=0.241]
Epoch 36, average_train_loss: 0.004128502303368283
Saved model state dict: ./model/transformer_36.pth
Epoch 37/200: 100%|██████████| 161/161 [01:02<00:00,  2.59it/s, loss (batch)=0.256]
Epoch 37, average_train_loss: 0.00411648999534031
Saved model state dict: ./model/transformer_37.pth
Epoch 38/200: 100%|██████████| 161/161 [01:02<00:00,  2.57it/s, loss (batch)=0.249]
Epoch 38, average_train_loss: 0.003910286745043621
Saved model state dict: ./model/transformer_38.pth
Epoch 39/200: 100%|██████████| 161/161 [00:55<00:00,  2.88it/s, loss (batch)=0.244]
Epoch 39, average_train_loss: 0.003732267299215181
Saved model state dict: ./model/transformer_39.pth
Epoch 40/200: 100%|██████████| 161/161 [00:50<00:00,  3.18it/s, loss (batch)=0.232]
Epoch 40, average_train_loss: 0.0037721956932757314
Saved model state dict: ./model/transformer_40.pth
Epoch 41/200: 100%|██████████| 161/161 [00:51<00:00,  3.14it/s, loss (batch)=0.239]
Epoch 41/200: 100%|██████████| 52/52 [05:44<00:00,  6.63s/it, val_loss (batch)=16.2]
Epoch 41, average_train_loss: 0.003502001161231898
Epoch 41, average_train_loss: 0.003502001161231898, average_val_loss: 0.4448403689479741
Saved model state dict: ./model/transformer_41.pth
Epoch 42/200: 100%|██████████| 161/161 [00:52<00:00,  3.05it/s, loss (batch)=0.189]
Epoch 42, average_train_loss: 0.003475262741807399
Saved model state dict: ./model/transformer_42.pth
Epoch 43/200: 100%|██████████| 161/161 [00:53<00:00,  2.99it/s, loss (batch)=0.182]
Epoch 43, average_train_loss: 0.003307965247095032
Saved model state dict: ./model/transformer_43.pth
Epoch 44/200: 100%|██████████| 161/161 [00:53<00:00,  3.03it/s, loss (batch)=0.207]
Epoch 44, average_train_loss: 0.0032009615653347243
Saved model state dict: ./model/transformer_44.pth
Epoch 45/200: 100%|██████████| 161/161 [00:54<00:00,  2.97it/s, loss (batch)=0.194]
Epoch 45, average_train_loss: 0.0031344208504393628
Saved model state dict: ./model/transformer_45.pth
Epoch 46/200: 100%|██████████| 161/161 [00:55<00:00,  2.89it/s, loss (batch)=0.172]
Epoch 46, average_train_loss: 0.0033368916495735562
Saved model state dict: ./model/transformer_46.pth
Epoch 47/200: 100%|██████████| 161/161 [00:53<00:00,  2.99it/s, loss (batch)=0.17] 
Epoch 47, average_train_loss: 0.0028464131644682722
Saved model state dict: ./model/transformer_47.pth
Epoch 48/200: 100%|██████████| 161/161 [00:51<00:00,  3.13it/s, loss (batch)=0.197]
Epoch 48, average_train_loss: 0.0028732283449860742
Saved model state dict: ./model/transformer_48.pth
Epoch 49/200: 100%|██████████| 161/161 [00:53<00:00,  2.99it/s, loss (batch)=0.204]
Epoch 49, average_train_loss: 0.00279530399974449
Saved model state dict: ./model/transformer_49.pth
Epoch 50/200: 100%|██████████| 161/161 [00:51<00:00,  3.11it/s, loss (batch)=0.167]
Epoch 50, average_train_loss: 0.0026763292077967627
Saved model state dict: ./model/transformer_50.pth
Epoch 51/200: 100%|██████████| 161/161 [00:54<00:00,  2.97it/s, loss (batch)=0.148]
Epoch 51/200: 100%|██████████| 52/52 [07:03<00:00,  8.14s/it, val_loss (batch)=18.4]
Epoch 51, average_train_loss: 0.0022241105773437094
Epoch 51, average_train_loss: 0.0022241105773437094, average_val_loss: 0.4928719998130022
Saved model state dict: ./model/transformer_51.pth
Epoch 52/200: 100%|██████████| 161/161 [00:53<00:00,  2.99it/s, loss (batch)=0.13] 
Epoch 52, average_train_loss: 0.002143185570125935
Saved model state dict: ./model/transformer_52.pth
Epoch 53/200: 100%|██████████| 161/161 [00:53<00:00,  3.03it/s, loss (batch)=0.127]
Epoch 53, average_train_loss: 0.002130206552714519
Saved model state dict: ./model/transformer_53.pth
Epoch 54/200: 100%|██████████| 161/161 [00:52<00:00,  3.08it/s, loss (batch)=0.12] 
Epoch 54, average_train_loss: 0.0020797242504057975
Saved model state dict: ./model/transformer_54.pth
Epoch 55/200: 100%|██████████| 161/161 [00:49<00:00,  3.23it/s, loss (batch)=0.137]
Epoch 55, average_train_loss: 0.002068649661226145
Saved model state dict: ./model/transformer_55.pth
Epoch 56/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.121]
Epoch 56, average_train_loss: 0.002063827469891222
Saved model state dict: ./model/transformer_56.pth
Epoch 57/200: 100%|██████████| 161/161 [00:51<00:00,  3.12it/s, loss (batch)=0.134]
Epoch 57, average_train_loss: 0.0020420532021916595
Saved model state dict: ./model/transformer_57.pth
Epoch 58/200: 100%|██████████| 161/161 [00:50<00:00,  3.18it/s, loss (batch)=0.126]
Epoch 58, average_train_loss: 0.001996271000737022
Saved model state dict: ./model/transformer_58.pth
Epoch 59/200: 100%|██████████| 161/161 [00:51<00:00,  3.14it/s, loss (batch)=0.12] 
Epoch 59, average_train_loss: 0.0019887931817003817
Saved model state dict: ./model/transformer_59.pth
Epoch 60/200: 100%|██████████| 161/161 [00:53<00:00,  3.01it/s, loss (batch)=0.124]
Epoch 60, average_train_loss: 0.0019981435507074132
Saved model state dict: ./model/transformer_60.pth
Epoch 61/200: 100%|██████████| 161/161 [00:52<00:00,  3.09it/s, loss (batch)=0.137]
Epoch 61/200: 100%|██████████| 52/52 [05:42<00:00,  6.59s/it, val_loss (batch)=18.2]
Epoch 61, average_train_loss: 0.0019379675122581138
Epoch 61, average_train_loss: 0.0019379675122581138, average_val_loss: 0.43874514504764855
Saved model state dict: ./model/transformer_61.pth
Epoch 62/200: 100%|██████████| 161/161 [00:50<00:00,  3.18it/s, loss (batch)=0.14] 
Epoch 62, average_train_loss: 0.001994362906392654
Saved model state dict: ./model/transformer_62.pth
Epoch 63/200: 100%|██████████| 161/161 [00:52<00:00,  3.06it/s, loss (batch)=0.112]
Epoch 63, average_train_loss: 0.0019479919144742707
Saved model state dict: ./model/transformer_63.pth
Epoch 64/200: 100%|██████████| 161/161 [00:51<00:00,  3.13it/s, loss (batch)=0.109]
Epoch 64, average_train_loss: 0.0018758873882994017
Saved model state dict: ./model/transformer_64.pth
Epoch 65/200: 100%|██████████| 161/161 [00:48<00:00,  3.31it/s, loss (batch)=0.0976]
Epoch 65, average_train_loss: 0.001845823910754276
Saved model state dict: ./model/transformer_65.pth
Epoch 66/200: 100%|██████████| 161/161 [00:48<00:00,  3.30it/s, loss (batch)=0.11] 
Epoch 66, average_train_loss: 0.0018277674878553253
Saved model state dict: ./model/transformer_66.pth
Epoch 67/200: 100%|██████████| 161/161 [00:52<00:00,  3.09it/s, loss (batch)=0.118]
Epoch 67, average_train_loss: 0.0018073840760403981
Saved model state dict: ./model/transformer_67.pth
Epoch 68/200: 100%|██████████| 161/161 [00:52<00:00,  3.04it/s, loss (batch)=0.121]
Epoch 68, average_train_loss: 0.0017824509603948625
Saved model state dict: ./model/transformer_68.pth
Epoch 69/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.106]
Epoch 69, average_train_loss: 0.0017801056503552511
Saved model state dict: ./model/transformer_69.pth
Epoch 70/200: 100%|██████████| 161/161 [00:53<00:00,  3.01it/s, loss (batch)=0.123]
Epoch 70, average_train_loss: 0.001764421510180585
Saved model state dict: ./model/transformer_70.pth
Epoch 71/200: 100%|██████████| 161/161 [01:03<00:00,  2.55it/s, loss (batch)=0.107]
Epoch 71/200: 100%|██████████| 52/52 [05:58<00:00,  6.89s/it, val_loss (batch)=15.3]
Epoch 71, average_train_loss: 0.0017318577438392505
Epoch 71, average_train_loss: 0.0017318577438392505, average_val_loss: 0.43349449489024716
Saved model state dict: ./model/transformer_71.pth
Epoch 72/200: 100%|██████████| 161/161 [00:53<00:00,  3.00it/s, loss (batch)=0.11] 
Epoch 72, average_train_loss: 0.0017640626827837048
Saved model state dict: ./model/transformer_72.pth
Epoch 73/200: 100%|██████████| 161/161 [00:54<00:00,  2.95it/s, loss (batch)=0.118]
Epoch 73, average_train_loss: 0.0018154359993071668
Saved model state dict: ./model/transformer_73.pth
Epoch 74/200: 100%|██████████| 161/161 [00:53<00:00,  3.03it/s, loss (batch)=0.0995]
Epoch 74, average_train_loss: 0.0016742498590204755
Saved model state dict: ./model/transformer_74.pth
Epoch 75/200: 100%|██████████| 161/161 [00:51<00:00,  3.13it/s, loss (batch)=0.0981]
Epoch 75, average_train_loss: 0.0016257045638978325
Saved model state dict: ./model/transformer_75.pth
Epoch 76/200: 100%|██████████| 161/161 [00:53<00:00,  3.01it/s, loss (batch)=0.1]   
Epoch 76, average_train_loss: 0.001618079423625594
Saved model state dict: ./model/transformer_76.pth
Epoch 77/200: 100%|██████████| 161/161 [00:54<00:00,  2.95it/s, loss (batch)=0.103] 
Epoch 77, average_train_loss: 0.0016311203590576534
Saved model state dict: ./model/transformer_77.pth
Epoch 78/200: 100%|██████████| 161/161 [00:55<00:00,  2.92it/s, loss (batch)=0.106] 
Epoch 78, average_train_loss: 0.0016157396218312227
Saved model state dict: ./model/transformer_78.pth
Epoch 79/200: 100%|██████████| 161/161 [00:53<00:00,  3.01it/s, loss (batch)=0.0891]
Epoch 79, average_train_loss: 0.0015466468997394791
Saved model state dict: ./model/transformer_79.pth
Epoch 80/200: 100%|██████████| 161/161 [00:53<00:00,  3.02it/s, loss (batch)=0.107] 
Epoch 80, average_train_loss: 0.0015345318781134097
Saved model state dict: ./model/transformer_80.pth
Epoch 81/200: 100%|██████████| 161/161 [00:53<00:00,  3.00it/s, loss (batch)=0.0992]
Epoch 81/200: 100%|██████████| 52/52 [05:56<00:00,  6.85s/it, val_loss (batch)=17.4]
Epoch 81, average_train_loss: 0.0016028464033628995
Epoch 81, average_train_loss: 0.0016028464033628995, average_val_loss: 0.43415610941572097
Saved model state dict: ./model/transformer_81.pth
Epoch 82/200: 100%|██████████| 161/161 [00:55<00:00,  2.92it/s, loss (batch)=0.107] 
Epoch 82, average_train_loss: 0.001498981558774696
Saved model state dict: ./model/transformer_82.pth
Epoch 83/200: 100%|██████████| 161/161 [00:57<00:00,  2.82it/s, loss (batch)=0.0958]
Epoch 83, average_train_loss: 0.0015276773417859197
Saved model state dict: ./model/transformer_83.pth
Epoch 84/200: 100%|██████████| 161/161 [00:57<00:00,  2.82it/s, loss (batch)=0.0922]
Epoch 84, average_train_loss: 0.001539538655930729
Saved model state dict: ./model/transformer_84.pth
Epoch 85/200: 100%|██████████| 161/161 [00:55<00:00,  2.90it/s, loss (batch)=0.0838]
Epoch 85, average_train_loss: 0.0015300496237840978
Saved model state dict: ./model/transformer_85.pth
Epoch 86/200: 100%|██████████| 161/161 [00:54<00:00,  2.96it/s, loss (batch)=0.101] 
Epoch 86, average_train_loss: 0.0014507761309514233
Saved model state dict: ./model/transformer_86.pth
Epoch 87/200: 100%|██████████| 161/161 [00:56<00:00,  2.85it/s, loss (batch)=0.0889]
Epoch 87, average_train_loss: 0.0014417237720983486
Saved model state dict: ./model/transformer_87.pth
Epoch 88/200: 100%|██████████| 161/161 [00:58<00:00,  2.76it/s, loss (batch)=0.105] 
Epoch 88, average_train_loss: 0.0014027704681444906
Saved model state dict: ./model/transformer_88.pth
Epoch 89/200: 100%|██████████| 161/161 [00:57<00:00,  2.80it/s, loss (batch)=0.0959]
Epoch 89, average_train_loss: 0.0014044480766251869
Saved model state dict: ./model/transformer_89.pth
Epoch 90/200: 100%|██████████| 161/161 [01:00<00:00,  2.68it/s, loss (batch)=0.0845]
Epoch 90, average_train_loss: 0.0014052212241216194
Saved model state dict: ./model/transformer_90.pth
Epoch 91/200: 100%|██████████| 161/161 [00:56<00:00,  2.87it/s, loss (batch)=0.0876]
Epoch 91/200: 100%|██████████| 52/52 [06:36<00:00,  7.63s/it, val_loss (batch)=16.6]
Epoch 91, average_train_loss: 0.0014049351881928478
Epoch 91, average_train_loss: 0.0014049351881928478, average_val_loss: 0.4158390414703953
Saved model state dict: ./model/transformer_91.pth
Epoch 92/200: 100%|██████████| 161/161 [00:56<00:00,  2.85it/s, loss (batch)=0.0824]
Epoch 92, average_train_loss: 0.0013713776301412877
Saved model state dict: ./model/transformer_92.pth
Epoch 93/200: 100%|██████████| 161/161 [00:57<00:00,  2.78it/s, loss (batch)=0.0886]
Epoch 93, average_train_loss: 0.0013440223961659033
Saved model state dict: ./model/transformer_93.pth
Epoch 94/200: 100%|██████████| 161/161 [00:56<00:00,  2.83it/s, loss (batch)=0.0869]
Epoch 94, average_train_loss: 0.0014732435466183428
Saved model state dict: ./model/transformer_94.pth
Epoch 95/200: 100%|██████████| 161/161 [00:58<00:00,  2.77it/s, loss (batch)=0.081] 
Epoch 95, average_train_loss: 0.0013413440122809772
Saved model state dict: ./model/transformer_95.pth
Epoch 96/200: 100%|██████████| 161/161 [00:57<00:00,  2.78it/s, loss (batch)=0.0897]
Epoch 96, average_train_loss: 0.0013166015054466036
Saved model state dict: ./model/transformer_96.pth
Epoch 97/200: 100%|██████████| 161/161 [00:55<00:00,  2.90it/s, loss (batch)=0.0735]
Epoch 97, average_train_loss: 0.0013385152981743897
Saved model state dict: ./model/transformer_97.pth
Epoch 98/200: 100%|██████████| 161/161 [00:53<00:00,  2.98it/s, loss (batch)=0.0788]
Epoch 98, average_train_loss: 0.0012718551481703012
Saved model state dict: ./model/transformer_98.pth
Epoch 99/200: 100%|██████████| 161/161 [00:55<00:00,  2.90it/s, loss (batch)=0.0798]
Epoch 99, average_train_loss: 0.0012927852812804114
Saved model state dict: ./model/transformer_99.pth
Epoch 100/200: 100%|██████████| 161/161 [00:54<00:00,  2.95it/s, loss (batch)=0.0844]
Epoch 100, average_train_loss: 0.0013253240956919501
Saved model state dict: ./model/transformer_100.pth
Epoch 101/200: 100%|██████████| 161/161 [00:57<00:00,  2.78it/s, loss (batch)=0.0707]
Epoch 101/200: 100%|██████████| 52/52 [06:35<00:00,  7.61s/it, val_loss (batch)=18.1]
Epoch 101, average_train_loss: 0.001140793437829272
Epoch 101, average_train_loss: 0.001140793437829272, average_val_loss: 0.4749587881793159
Saved model state dict: ./model/transformer_101.pth
Epoch 102/200: 100%|██████████| 161/161 [00:56<00:00,  2.87it/s, loss (batch)=0.0657]
Epoch 102, average_train_loss: 0.0011045149482199236
Saved model state dict: ./model/transformer_102.pth
Epoch 103/200: 100%|██████████| 161/161 [00:55<00:00,  2.92it/s, loss (batch)=0.07]  
Epoch 103, average_train_loss: 0.0010971645398477332
Saved model state dict: ./model/transformer_103.pth
Epoch 104/200: 100%|██████████| 161/161 [00:58<00:00,  2.77it/s, loss (batch)=0.0678]
Epoch 104, average_train_loss: 0.001088375302448966
Saved model state dict: ./model/transformer_104.pth
Epoch 105/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.0603]
Epoch 105, average_train_loss: 0.0010835858846649465
Saved model state dict: ./model/transformer_105.pth
Epoch 106/200: 100%|██████████| 161/161 [00:56<00:00,  2.83it/s, loss (batch)=0.0643]
Epoch 106, average_train_loss: 0.0010835078877380817
Saved model state dict: ./model/transformer_106.pth
Epoch 107/200: 100%|██████████| 161/161 [00:56<00:00,  2.83it/s, loss (batch)=0.0696]
Epoch 107, average_train_loss: 0.0010836762275836143
Saved model state dict: ./model/transformer_107.pth
Epoch 108/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0715]
Epoch 108, average_train_loss: 0.001076839564371941
Saved model state dict: ./model/transformer_108.pth
Epoch 109/200: 100%|██████████| 161/161 [00:54<00:00,  2.96it/s, loss (batch)=0.0701]
Epoch 109, average_train_loss: 0.0010723568845441172
Saved model state dict: ./model/transformer_109.pth
Epoch 110/200: 100%|██████████| 161/161 [00:57<00:00,  2.81it/s, loss (batch)=0.0653]
Epoch 110, average_train_loss: 0.0010708436419271188
Saved model state dict: ./model/transformer_110.pth
Epoch 111/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0698]
Epoch 111/200: 100%|██████████| 52/52 [06:31<00:00,  7.54s/it, val_loss (batch)=15]  
Epoch 111, average_train_loss: 0.0010676933743837295
Epoch 111, average_train_loss: 0.0010676933743837295, average_val_loss: 0.4733996717103737
Saved model state dict: ./model/transformer_111.pth
Epoch 112/200: 100%|██████████| 161/161 [00:58<00:00,  2.75it/s, loss (batch)=0.076] 
Epoch 112, average_train_loss: 0.0010610509599559826
Saved model state dict: ./model/transformer_112.pth
Epoch 113/200: 100%|██████████| 161/161 [00:54<00:00,  2.95it/s, loss (batch)=0.0673]
Epoch 113, average_train_loss: 0.0010726511189433614
Saved model state dict: ./model/transformer_113.pth
Epoch 114/200: 100%|██████████| 161/161 [00:52<00:00,  3.06it/s, loss (batch)=0.0646]
Epoch 114, average_train_loss: 0.001056059391532141
Saved model state dict: ./model/transformer_114.pth
Epoch 115/200: 100%|██████████| 161/161 [00:54<00:00,  2.97it/s, loss (batch)=0.079] 
Epoch 115, average_train_loss: 0.0010461997784998738
Saved model state dict: ./model/transformer_115.pth
Epoch 116/200: 100%|██████████| 161/161 [00:56<00:00,  2.87it/s, loss (batch)=0.065] 
Epoch 116, average_train_loss: 0.0010581246934175468
Saved model state dict: ./model/transformer_116.pth
Epoch 117/200: 100%|██████████| 161/161 [00:57<00:00,  2.82it/s, loss (batch)=0.0602]
Epoch 117, average_train_loss: 0.0010373144593983294
Saved model state dict: ./model/transformer_117.pth
Epoch 118/200: 100%|██████████| 161/161 [00:52<00:00,  3.06it/s, loss (batch)=0.0666]
Epoch 118, average_train_loss: 0.0010330709333326161
Saved model state dict: ./model/transformer_118.pth
Epoch 119/200: 100%|██████████| 161/161 [00:51<00:00,  3.15it/s, loss (batch)=0.0642]
Epoch 119, average_train_loss: 0.0010266843364521282
Saved model state dict: ./model/transformer_119.pth
Epoch 120/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0629]
Epoch 120, average_train_loss: 0.0010209802929164954
Saved model state dict: ./model/transformer_120.pth
Epoch 121/200: 100%|██████████| 161/161 [00:56<00:00,  2.85it/s, loss (batch)=0.0627]
Epoch 121/200: 100%|██████████| 52/52 [06:38<00:00,  7.66s/it, val_loss (batch)=21.3]
Epoch 121, average_train_loss: 0.0010160346351285833
Epoch 121, average_train_loss: 0.0010160346351285833, average_val_loss: 0.48064342647057845
Saved model state dict: ./model/transformer_121.pth
Epoch 122/200: 100%|██████████| 161/161 [00:57<00:00,  2.81it/s, loss (batch)=0.0634]
Epoch 122, average_train_loss: 0.0010233681858451426
Saved model state dict: ./model/transformer_122.pth
Epoch 123/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.0599]
Epoch 123, average_train_loss: 0.0010100727206160131
Saved model state dict: ./model/transformer_123.pth
Epoch 124/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.063] 
Epoch 124, average_train_loss: 0.001004584945775347
Saved model state dict: ./model/transformer_124.pth
Epoch 125/200: 100%|██████████| 161/161 [00:58<00:00,  2.76it/s, loss (batch)=0.0661]
Epoch 125, average_train_loss: 0.000999407309248438
Saved model state dict: ./model/transformer_125.pth
Epoch 126/200: 100%|██████████| 161/161 [00:55<00:00,  2.90it/s, loss (batch)=0.0629]
Epoch 126, average_train_loss: 0.0009903777025849856
Saved model state dict: ./model/transformer_126.pth
Epoch 127/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0649]
Epoch 127, average_train_loss: 0.0009956590169796573
Saved model state dict: ./model/transformer_127.pth
Epoch 128/200: 100%|██████████| 161/161 [00:58<00:00,  2.74it/s, loss (batch)=0.058] 
Epoch 128, average_train_loss: 0.000989721126795605
Saved model state dict: ./model/transformer_128.pth
Epoch 129/200: 100%|██████████| 161/161 [00:55<00:00,  2.89it/s, loss (batch)=0.0633]
Epoch 129, average_train_loss: 0.0009853793820951686
Saved model state dict: ./model/transformer_129.pth
Epoch 130/200: 100%|██████████| 161/161 [00:59<00:00,  2.71it/s, loss (batch)=0.0592]
Epoch 130, average_train_loss: 0.0009711644828360211
Saved model state dict: ./model/transformer_130.pth
Epoch 131/200: 100%|██████████| 161/161 [00:54<00:00,  2.94it/s, loss (batch)=0.0584]
Epoch 131/200: 100%|██████████| 52/52 [06:46<00:00,  7.82s/it, val_loss (batch)=20.7]
Epoch 131, average_train_loss: 0.0009766712540795308
Epoch 131, average_train_loss: 0.0009766712540795308, average_val_loss: 0.46089852735911535
Saved model state dict: ./model/transformer_131.pth
Epoch 132/200: 100%|██████████| 161/161 [00:59<00:00,  2.70it/s, loss (batch)=0.0587]
Epoch 132, average_train_loss: 0.000972704159729593
Saved model state dict: ./model/transformer_132.pth
Epoch 133/200: 100%|██████████| 161/161 [00:54<00:00,  2.94it/s, loss (batch)=0.0573]
Epoch 133, average_train_loss: 0.0009641868267714797
Saved model state dict: ./model/transformer_133.pth
Epoch 134/200: 100%|██████████| 161/161 [00:56<00:00,  2.83it/s, loss (batch)=0.0615]
Epoch 134, average_train_loss: 0.0009554198637841424
Saved model state dict: ./model/transformer_134.pth
Epoch 135/200: 100%|██████████| 161/161 [00:58<00:00,  2.76it/s, loss (batch)=0.0649]
Epoch 135, average_train_loss: 0.0009556068947046615
Saved model state dict: ./model/transformer_135.pth
Epoch 136/200: 100%|██████████| 161/161 [01:00<00:00,  2.65it/s, loss (batch)=0.0588]
Epoch 136, average_train_loss: 0.0009628508863347093
Saved model state dict: ./model/transformer_136.pth
Epoch 137/200: 100%|██████████| 161/161 [00:54<00:00,  2.95it/s, loss (batch)=0.0628]
Epoch 137, average_train_loss: 0.0009482173611634238
Saved model state dict: ./model/transformer_137.pth
Epoch 138/200: 100%|██████████| 161/161 [00:58<00:00,  2.78it/s, loss (batch)=0.0651]
Epoch 138, average_train_loss: 0.0009367726372906879
Saved model state dict: ./model/transformer_138.pth
Epoch 139/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.0639]
Epoch 139, average_train_loss: 0.0009502299782006715
Saved model state dict: ./model/transformer_139.pth
Epoch 140/200: 100%|██████████| 161/161 [00:56<00:00,  2.87it/s, loss (batch)=0.0573]
Epoch 140, average_train_loss: 0.0009358260642975677
Saved model state dict: ./model/transformer_140.pth
Epoch 141/200: 100%|██████████| 161/161 [00:54<00:00,  2.98it/s, loss (batch)=0.0622]
Epoch 141/200: 100%|██████████| 52/52 [06:32<00:00,  7.55s/it, val_loss (batch)=16.7]
Epoch 141, average_train_loss: 0.0009343097404468921
Epoch 141, average_train_loss: 0.0009343097404468921, average_val_loss: 0.4731093249420898
Saved model state dict: ./model/transformer_141.pth
Epoch 142/200: 100%|██████████| 161/161 [00:57<00:00,  2.82it/s, loss (batch)=0.064] 
Epoch 142, average_train_loss: 0.0009281092915412058
Saved model state dict: ./model/transformer_142.pth
Epoch 143/200: 100%|██████████| 161/161 [00:54<00:00,  2.93it/s, loss (batch)=0.0571]
Epoch 143, average_train_loss: 0.0009318669516752598
Saved model state dict: ./model/transformer_143.pth
Epoch 144/200: 100%|██████████| 161/161 [00:55<00:00,  2.89it/s, loss (batch)=0.0592]
Epoch 144, average_train_loss: 0.0009201048915932929
Saved model state dict: ./model/transformer_144.pth
Epoch 145/200: 100%|██████████| 161/161 [00:55<00:00,  2.90it/s, loss (batch)=0.0592]
Epoch 145, average_train_loss: 0.0009595341464921567
Saved model state dict: ./model/transformer_145.pth
Epoch 146/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.0605]
Epoch 146, average_train_loss: 0.0009134736936984152
Saved model state dict: ./model/transformer_146.pth
Epoch 147/200: 100%|██████████| 161/161 [00:56<00:00,  2.85it/s, loss (batch)=0.0584]
Epoch 147, average_train_loss: 0.0009056162722637496
Saved model state dict: ./model/transformer_147.pth
Epoch 148/200: 100%|██████████| 161/161 [00:58<00:00,  2.77it/s, loss (batch)=0.061] 
Epoch 148, average_train_loss: 0.0008989212949737658
Saved model state dict: ./model/transformer_148.pth
Epoch 149/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.0521]
Epoch 149, average_train_loss: 0.0008991899126925533
Saved model state dict: ./model/transformer_149.pth
Epoch 150/200: 100%|██████████| 161/161 [00:59<00:00,  2.71it/s, loss (batch)=0.0599]
Epoch 150, average_train_loss: 0.0009003849517658967
Saved model state dict: ./model/transformer_150.pth
Epoch 151/200: 100%|██████████| 161/161 [00:57<00:00,  2.78it/s, loss (batch)=0.0533]
Epoch 151/200: 100%|██████████| 52/52 [06:39<00:00,  7.69s/it, val_loss (batch)=17.2]
Epoch 151, average_train_loss: 0.0008412471144372011
Epoch 151, average_train_loss: 0.0008412471144372011, average_val_loss: 0.4576859759444565
Saved model state dict: ./model/transformer_151.pth
Epoch 152/200: 100%|██████████| 161/161 [00:57<00:00,  2.80it/s, loss (batch)=0.0481]
Epoch 152, average_train_loss: 0.0008310593647219589
Saved model state dict: ./model/transformer_152.pth
Epoch 153/200: 100%|██████████| 161/161 [00:57<00:00,  2.80it/s, loss (batch)=0.0539]
Epoch 153, average_train_loss: 0.0008281961155296731
Saved model state dict: ./model/transformer_153.pth
Epoch 154/200: 100%|██████████| 161/161 [00:59<00:00,  2.73it/s, loss (batch)=0.0523]
Epoch 154, average_train_loss: 0.0008246452647358711
Saved model state dict: ./model/transformer_154.pth
Epoch 155/200: 100%|██████████| 161/161 [00:53<00:00,  2.98it/s, loss (batch)=0.0512]
Epoch 155, average_train_loss: 0.0008236965047094443
Saved model state dict: ./model/transformer_155.pth
Epoch 156/200: 100%|██████████| 161/161 [00:58<00:00,  2.74it/s, loss (batch)=0.0561]
Epoch 156, average_train_loss: 0.0008239766671613183
Saved model state dict: ./model/transformer_156.pth
Epoch 157/200: 100%|██████████| 161/161 [00:54<00:00,  2.94it/s, loss (batch)=0.0524]
Epoch 157, average_train_loss: 0.0008229957645706889
Saved model state dict: ./model/transformer_157.pth
Epoch 158/200: 100%|██████████| 161/161 [00:56<00:00,  2.87it/s, loss (batch)=0.0504]
Epoch 158, average_train_loss: 0.0008243289410823991
Saved model state dict: ./model/transformer_158.pth
Epoch 159/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0475]
Epoch 159, average_train_loss: 0.0008166149075634705
Saved model state dict: ./model/transformer_159.pth
Epoch 160/200: 100%|██████████| 161/161 [00:55<00:00,  2.88it/s, loss (batch)=0.047] 
Epoch 160, average_train_loss: 0.0008168608591362765
Saved model state dict: ./model/transformer_160.pth
Epoch 161/200: 100%|██████████| 161/161 [00:58<00:00,  2.75it/s, loss (batch)=0.0529]
Epoch 161/200: 100%|██████████| 52/52 [06:32<00:00,  7.56s/it, val_loss (batch)=20.3]
Epoch 161, average_train_loss: 0.0008166780399975286
Epoch 161, average_train_loss: 0.0008166780399975286, average_val_loss: 0.4619572046061544
Saved model state dict: ./model/transformer_161.pth
Epoch 162/200: 100%|██████████| 161/161 [01:01<00:00,  2.61it/s, loss (batch)=0.0504]
Epoch 162, average_train_loss: 0.0008149481819696262
Saved model state dict: ./model/transformer_162.pth
Epoch 163/200: 100%|██████████| 161/161 [00:55<00:00,  2.89it/s, loss (batch)=0.0528]
Epoch 163, average_train_loss: 0.0008133250765082037
Saved model state dict: ./model/transformer_163.pth
Epoch 164/200: 100%|██████████| 161/161 [00:57<00:00,  2.80it/s, loss (batch)=0.0491]
Epoch 164, average_train_loss: 0.0008101928719575265
Saved model state dict: ./model/transformer_164.pth
Epoch 165/200: 100%|██████████| 161/161 [00:59<00:00,  2.72it/s, loss (batch)=0.0534]
Epoch 165, average_train_loss: 0.0008106031077070295
Saved model state dict: ./model/transformer_165.pth
Epoch 166/200: 100%|██████████| 161/161 [00:58<00:00,  2.74it/s, loss (batch)=0.0518]
Epoch 166, average_train_loss: 0.0008089944459595953
Saved model state dict: ./model/transformer_166.pth
Epoch 167/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.051] 
Epoch 167, average_train_loss: 0.0008065964815683061
Saved model state dict: ./model/transformer_167.pth
Epoch 168/200: 100%|██████████| 161/161 [00:56<00:00,  2.86it/s, loss (batch)=0.0507]
Epoch 168, average_train_loss: 0.0008036316562240298
Saved model state dict: ./model/transformer_168.pth
Epoch 169/200: 100%|██████████| 161/161 [00:56<00:00,  2.83it/s, loss (batch)=0.0505]
Epoch 169, average_train_loss: 0.000801786244127581
Saved model state dict: ./model/transformer_169.pth
Epoch 170/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.0494]
Epoch 170, average_train_loss: 0.0007993512994863638
Saved model state dict: ./model/transformer_170.pth
Epoch 171/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0505]
Epoch 171/200: 100%|██████████| 52/52 [06:34<00:00,  7.59s/it, val_loss (batch)=19.1]
Epoch 171, average_train_loss: 0.0007992513817620201
Epoch 171, average_train_loss: 0.0007992513817620201, average_val_loss: 0.44615205167601835
Saved model state dict: ./model/transformer_171.pth
Epoch 172/200: 100%|██████████| 161/161 [00:58<00:00,  2.75it/s, loss (batch)=0.0533]
Epoch 172, average_train_loss: 0.0008006500309496034
Saved model state dict: ./model/transformer_172.pth
Epoch 173/200: 100%|██████████| 161/161 [00:56<00:00,  2.84it/s, loss (batch)=0.0485]
Epoch 173, average_train_loss: 0.000793883881772451
Saved model state dict: ./model/transformer_173.pth
Epoch 174/200: 100%|██████████| 161/161 [00:55<00:00,  2.92it/s, loss (batch)=0.0566]
Epoch 174, average_train_loss: 0.0007932302347343459
Saved model state dict: ./model/transformer_174.pth
Epoch 175/200: 100%|██████████| 161/161 [00:58<00:00,  2.75it/s, loss (batch)=0.051] 
Epoch 175, average_train_loss: 0.0007908661337800802
Saved model state dict: ./model/transformer_175.pth
Epoch 176/200: 100%|██████████| 161/161 [00:57<00:00,  2.82it/s, loss (batch)=0.0505]
Epoch 176, average_train_loss: 0.0007899364376844178
Saved model state dict: ./model/transformer_176.pth
Epoch 177/200: 100%|██████████| 161/161 [00:55<00:00,  2.93it/s, loss (batch)=0.049] 
Epoch 177, average_train_loss: 0.0007915575728553764
Saved model state dict: ./model/transformer_177.pth
Epoch 178/200: 100%|██████████| 161/161 [00:56<00:00,  2.85it/s, loss (batch)=0.0499]
Epoch 178, average_train_loss: 0.0007873952233376599
Saved model state dict: ./model/transformer_178.pth
Epoch 179/200: 100%|██████████| 161/161 [00:59<00:00,  2.69it/s, loss (batch)=0.0517]
Epoch 179, average_train_loss: 0.0007857498968336482
Saved model state dict: ./model/transformer_179.pth
Epoch 180/200: 100%|██████████| 161/161 [01:00<00:00,  2.66it/s, loss (batch)=0.0527]
Epoch 180, average_train_loss: 0.0007833803802127436
Saved model state dict: ./model/transformer_180.pth
Epoch 181/200: 100%|██████████| 161/161 [00:55<00:00,  2.92it/s, loss (batch)=0.0482]
Epoch 181/200: 100%|██████████| 52/52 [06:14<00:00,  7.21s/it, val_loss (batch)=19.7]
Epoch 181, average_train_loss: 0.0007792011585172628
Epoch 181, average_train_loss: 0.0007792011585172628, average_val_loss: 0.4708299005498576
Saved model state dict: ./model/transformer_181.pth
Epoch 182/200: 100%|██████████| 161/161 [00:56<00:00,  2.87it/s, loss (batch)=0.0537]
Epoch 182, average_train_loss: 0.0007772990462027404
Saved model state dict: ./model/transformer_182.pth
Epoch 183/200: 100%|██████████| 161/161 [00:56<00:00,  2.85it/s, loss (batch)=0.0467]
Epoch 183, average_train_loss: 0.0007800558093096961
Saved model state dict: ./model/transformer_183.pth
Epoch 184/200: 100%|██████████| 161/161 [00:54<00:00,  2.98it/s, loss (batch)=0.0512]
Epoch 184, average_train_loss: 0.0007757911045275264
Saved model state dict: ./model/transformer_184.pth
Epoch 185/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.0522]
Epoch 185, average_train_loss: 0.0007742449264378357
Saved model state dict: ./model/transformer_185.pth
Epoch 186/200: 100%|██████████| 161/161 [00:55<00:00,  2.91it/s, loss (batch)=0.048] 
Epoch 186, average_train_loss: 0.0007734087321879326
Saved model state dict: ./model/transformer_186.pth
Epoch 187/200: 100%|██████████| 161/161 [00:53<00:00,  3.02it/s, loss (batch)=0.0529]
Epoch 187, average_train_loss: 0.0007714957493303719
Saved model state dict: ./model/transformer_187.pth
Epoch 188/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.0489]
Epoch 188, average_train_loss: 0.0007727137213938999
Saved model state dict: ./model/transformer_188.pth
Epoch 189/200: 100%|██████████| 161/161 [00:58<00:00,  2.75it/s, loss (batch)=0.0485]
Epoch 189, average_train_loss: 0.0007682022423600607
Saved model state dict: ./model/transformer_189.pth
Epoch 190/200: 100%|██████████| 161/161 [00:55<00:00,  2.92it/s, loss (batch)=0.0507]
Epoch 190, average_train_loss: 0.0007695967966690478
Saved model state dict: ./model/transformer_190.pth
Epoch 191/200: 100%|██████████| 161/161 [00:54<00:00,  2.97it/s, loss (batch)=0.0503]
Epoch 191/200: 100%|██████████| 52/52 [06:24<00:00,  7.39s/it, val_loss (batch)=20.2]
Epoch 191, average_train_loss: 0.000768827100720697
Epoch 191, average_train_loss: 0.000768827100720697, average_val_loss: 0.4332754005967322
Saved model state dict: ./model/transformer_191.pth
Epoch 192/200: 100%|██████████| 161/161 [00:57<00:00,  2.79it/s, loss (batch)=0.0463]
Epoch 192, average_train_loss: 0.0007638103320385766
Saved model state dict: ./model/transformer_192.pth
Epoch 193/200: 100%|██████████| 161/161 [00:55<00:00,  2.90it/s, loss (batch)=0.0481]
Epoch 193, average_train_loss: 0.0007639138461692839
Saved model state dict: ./model/transformer_193.pth
Epoch 194/200: 100%|██████████| 161/161 [00:53<00:00,  2.99it/s, loss (batch)=0.0462]
Epoch 194, average_train_loss: 0.0007635193571321983
Saved model state dict: ./model/transformer_194.pth
Epoch 195/200: 100%|██████████| 161/161 [00:57<00:00,  2.80it/s, loss (batch)=0.0475]
Epoch 195, average_train_loss: 0.0007583880240649302
Saved model state dict: ./model/transformer_195.pth
Epoch 196/200: 100%|██████████| 161/161 [00:52<00:00,  3.07it/s, loss (batch)=0.0468]
Epoch 196, average_train_loss: 0.0007592594432018733
Saved model state dict: ./model/transformer_196.pth
Epoch 197/200: 100%|██████████| 161/161 [01:02<00:00,  2.58it/s, loss (batch)=0.0474]
Epoch 197, average_train_loss: 0.0007588414014425557
Saved model state dict: ./model/transformer_197.pth
Epoch 198/200: 100%|██████████| 161/161 [00:52<00:00,  3.04it/s, loss (batch)=0.0465]
Epoch 198, average_train_loss: 0.0007544866441843884
Saved model state dict: ./model/transformer_198.pth
Epoch 199/200: 100%|██████████| 161/161 [00:53<00:00,  3.03it/s, loss (batch)=0.0442]
Epoch 199, average_train_loss: 0.0007539206973997057
Saved model state dict: ./model/transformer_199.pth
Epoch 200/200: 100%|██████████| 161/161 [00:51<00:00,  3.14it/s, loss (batch)=0.0474]
Epoch 200, average_train_loss: 0.0007562023529345594
Saved model state dict: ./model/transformer_200.pth
Average MAE: 0.05602161405733064
Average MSE: 0.5502673067150238